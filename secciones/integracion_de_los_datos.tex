Partiendo de las 3 tablas originales, la eliminación de variables, el agregado de los nuevos atributos y por último las transformaciones realizadas (todas vistas en las seciones anteriores), se genera un tablón principal. El mismo se llama \textbf{\textit{``baseline\_2009.csv"}}. \\

Dicho tablón también fue generado en el script \textit{``Giar 20-09.ipynb"} luego de hacer el preprocesamiento.

A continuación de presenta una muestra aleatoria pero invertiremos las filas por columnas para que entre en la hoja:

\input{tablas/baseline_sample.tex}




\comentarioinvisible{vale la pena hacer estadisticos aca ? ahora son todos numericos (la mayoria)}

\subsection{Exploración de datos Integrados}

\hypertarget{anuxe1lisis-estaduxedstico}{%
	\subsubsection{Análisis Estadístico}\label{anuxe1lisis-estaduxedstico}}

A continuación se realiza un breve análisis estadístico sobre como
quedan los campos en el tablón ``Baseline\_2009'' después de la
integración de la información, agregación de campos y campos calculados:

\input{tablas/tablon_est_cal.tex}

\input{tablas/tablon_est_cat.tex}

\input{tablas/tablon_est_num1.tex}

\input{tablas/tablon_est_num2.tex}


\clearpage

\hypertarget{dataset-supervisado-valores-en-funciuxf3n-de-la-clase}{%
	\subparagraph{Dataset Supervisado: Valores en función de la
		clase}\label{dataset-supervisado-valores-en-funciuxf3n-de-la-clase}}

Como es un dataset supervisado, podría ser interesante ver los valores
separados por clase. Por lo tanto el dataset y con el objeto solamente
de realizar un análisis exploratorio, se divide según la clase y se
realizan los estadísticos nuevamente.

\input{tablas/tablon_no_deserto_est_cal.tex}

\input{tablas/tablon_no_deserto_est_cat.tex}

\input{tablas/tablon_no_deserto_est_num1.tex}

\input{tablas/tablon_no_deserto_est_num2.tex}

\input{tablas/tablon_deserto_est.tex}




%\includegraphics{Analisis_tablon_baseline_2009_files/figure-latex/unnamed-chunk-12-1.pdf}
%\includegraphics{Analisis_tablon_baseline_2009_files/figure-latex/unnamed-chunk-12-2.pdf}
%\includegraphics{Analisis_tablon_baseline_2009_files/figure-latex/unnamed-chunk-12-3.pdf}



\begin{figure}[!htb]
	\centering
	\includegraphics{imagenes/imagenes/gg_explo_tablon_grupo.png}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Análisis Univariado por grupos}
	\label{fig:tablon_boxplot_grupo}
\end{figure}

\begin{figure}[!htb]
	\centering
	\includegraphics{imagenes/imagenes/gg_explo_tablon_tipo_aprob.png}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Análisis Univariado por Tipo de Aprobación}
	\label{fig:tablon_boxplot_tipoAprobacion}
\end{figure}

\begin{figure}[!htb]
	\centering
	\includegraphics{imagenes/imagenes/gg_explo_tablon_tipo_recur.png}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Análisis Univariado por tipo de resursada}
	\label{fig:tablon_boxplot_tipoRecursada}
\end{figure}

\clearpage

\hypertarget{observaciones}{%
	\paragraph{Observaciones}\label{observaciones}}

De las tablas y gráficos anteriores podemos extraer la siguiente
información:

\begin{itemize}
	\item
	El dataset se encuentra balanceado. 43.88 \% de los alumnos del
	dataset desertó mientras que el 56.12 \% sigue en carrera.
	\item
	La variable \textbf{EsTecnico} tiene un 13.32\% de datos nulos.
	Dependiendo el método que se use podrá tolerarse o no. En los casos
	que no se pueda tolerar, se tendrá que imputar algún valor o se podrá
	optar por descartar la variable.
	\item
	El valor mínimo de la variable \textbf{edad\_al\_ingreso} es 11. Un
	valor muy bajo y puede tratarse de un error. Se analizaron la cantidad
	de casos que existen en que esta variable tiene un valor menor a 17,
	que es la mínima edad que podría entrar un estudiante a la universidad
	respetando todos los ciclos lectivos sin adelantar ninguno de las
	etapas de estudio anteriores, y dicho valor es de 4 observaciones. Las
	cuales representan una cantidad insignificante respecto del total de
	observaciones 4558 (0.06\%). Por lo tanto al no poder verificarlo por
	el momento se decide dejarlo.
\end{itemize}

\hypertarget{correlaciuxf3n-entre-todas-las-variables}{%
	\paragraph{Correlación entre todas las
		variables}\label{correlaciuxf3n-entre-todas-las-variables}}

%\includegraphics{Analisis_tablon_baseline_2009_files/figure-latex/unnamed-chunk-15-1.pdf}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.98\textwidth]{imagenes/imagenes/gg_corr_todas_variables_leyenda.png}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Análisis Univariado por tipo de resursada}
	\label{fig:tablon_correlacion}
\end{figure}

\hypertarget{correlaciuxf3n-entre-las-variables-y-la-clase}{%
	\paragraph{Correlación entre las variables y la
		clase}\label{correlaciuxf3n-entre-las-variables-y-la-clase}}

Si bien la clase es categórica y la mayoría de las variables son
numéricas, podemos convertir la clase en númerica convirtiendo los casos
positivos en 1 y los negativos en 0. De esta forma podemos analizar por
el coeficiente de correlación si es que existen variables predictoras
que sigan o se acerquen al comportamiento de la clase. Como veremos en
la sigueinte tabla, no hay una relación muy directa entre cada variable
individual con la clase convertid en numérica.

\input{tablas/tablon_correl_clase.tex}


\subsubsection{Análisis de Variables Importantes}\label{analisis-var_importantes}

Incluir un exceso de variables en el modelo suele traer aparejado una disminución de la capacidad predictiva de un modelo cuando se expone a nuevos datos (overfitting). \\
Se realizan múltiples evaluaciones de modelos de RandomForest con bootstrapping generados mediante incorporación y eliminación de predictores con la finalidad de identificar la combinación óptima. Este análisis de realiza unicamente con el datset de train para que los valores de test no influyan en este procedimiento.\\

En la tabla \ref{tab:top_10_rfe_accuracy} se detallan los mejores 10 modelos obtenidos a partir de toda la combinación posibles. Puede observarse que el mejor modelo a juzgar por la métrica Accuracy es el que se entreno solamente con 10 predictores de los 25 que cuenta el datset completo. Dichos predictores son: 
``ciclo\_lectivo\_de\_cursada",``tipo\_de\_aprobacion\_libre", ``Turno\_Noche", ``tipo\_de\_aprobacion\_no\_firmo", ``Aprobado", ``Turno\_Tarde", ``Nota\_max\_prom", ``tipo\_de\_aprobacion\_firmo", ``Turno\_Manana" y ``cant\_resursada\_regular".\\

Asimismo, en la figura \ref{fig:rfe_evolucion_accuracy} se puede observar la evolución de la mátrica accuracy en función de la cantidad de variables que toma el modelo. La dispersión en este caso está asociado a los distintos valores de accuracy que tiene cada modelo ejecutado en cross validation como así también está conplemtado todas las combinaciones de variables posibles con la cantidad que marca el eje x.\\
Ademas de que al usar menos variables se necesita menos poder de computo, es más fácil la interpretación que se podrá hacer y tendremos una menor dispersión final.

\begin{table}[!h]
	
	\caption{\label{tab:top_10_rfe_accuracy}Top 10 Modelos con cantidad de variables seleccionadas según Accuracy}
	\centering
	\begin{tabular}[t]{rrr}
		\toprule
		\rowcolor{black}  \multicolumn{1}{c}{\textcolor{white}{\textbf{Variables}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{media\_accuracy}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{media\_kappa}}}\\
		\midrule
		\rowcolor{gray!6}  10 & 0.8388631 & 0.6690887\\
		18 & 0.8385668 & 0.6687514\\
		\rowcolor{gray!6}  11 & 0.8381883 & 0.6678640\\
		19 & 0.8381476 & 0.6679149\\
		\rowcolor{gray!6}  17 & 0.8380654 & 0.6677621\\
		\addlinespace
		9 & 0.8377655 & 0.6670357\\
		\rowcolor{gray!6}  23 & 0.8368520 & 0.6655250\\
		20 & 0.8360972 & 0.6636373\\
		\rowcolor{gray!6}  15 & 0.8360919 & 0.6637290\\
		22 & 0.8355010 & 0.6625480\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{figure}[!htb]
	\centering
	\includegraphics{imagenes/variables/rfe_evolucion_accuracy-1.pdf}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Evolución de l Métrica Accuracy en función de la cantidad de variables usadas por el modelo}
	\label{fig:rfe_evolucion_accuracy}
\end{figure}

\paragraph{influencia de variables}
Tras ajustar cada uno de estos modelos, se recalcula la influencia de cada variable. De esta forma, para cada tamaño de modelo, se obtiene un ranking de la importancia promedio de las variables. Los resultados se pueden observar en \ref{tab:tf_rfe_influencia_variables} y \ref{fig:rfe_influencia_var} donde existe una variable que claramente influye mucho mas en los resultados en comparación con los otros predictores.

\begin{table}[!h]
	
	\caption{\label{tab:tf_rfe_influencia_variables}Influencia de variables en el resultado}
	\centering
	\begin{tabular}[t]{lrr}
		\toprule
		\rowcolor{black}  \multicolumn{1}{c}{\textcolor{white}{\textbf{var}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{media\_influencia}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{sd\_influencia}}}\\
		\midrule
		\rowcolor{gray!6}  ciclo\_lectivo\_de\_cursada & 89.84029 & 2.9668673\\
		tipo\_de\_aprobacion\_libre & 46.34285 & 2.2575528\\
		\rowcolor{gray!6}  Turno\_Noche & 38.07504 & 1.7175035\\
		tipo\_de\_aprobacion\_no\_firmo & 38.05189 & 1.5399760\\
		\rowcolor{gray!6}  Aprobado & 35.80734 & 1.1307306\\
		\addlinespace
		Turno\_Tarde & 35.67467 & 1.5035133\\
		\rowcolor{gray!6}  tipo\_de\_aprobacion\_firmo & 35.28770 & 0.6960169\\
		Nota\_max\_prom & 35.14407 & 2.3991503\\
		\rowcolor{gray!6}  Turno\_Manana & 34.30645 & 1.5999039\\
		cant\_resursada\_regular & 32.25476 & 1.1929776\\
		\addlinespace
		\rowcolor{gray!6}  edad\_al\_ingreso & 31.90459 & 0.1024266\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{figure}[!htb]
	\centering
	\includegraphics{imagenes/variables/influencia_de_variables-1.pdf}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Influencia de las variables mas importances sobre el resultado}
	\label{fig:rfe_influencia_var}
\end{figure}

\clearpage



\subsubsection{Análisis de Variables Importantes: Dataset sin Variable ciclo\_lectivo\_de\_cursada}\label{analisis-var_importantes-2}

De acuerdo al análisis de Variables anterior, se decide eliminar la variable mas influyente en el resultado (``ciclo\_lectivo\_de\_cursada'') y analizar el dataset resultante. Esto se realiza para verificar que aún sin esa información es posible armar buenos modelos predictivos.

Se utilizan la misma técnica anterior de múltiples evaluaciones con  modelos de RandomForest con bootstrapping generados mediante incorporación y eliminación de predictores con la finalidad de identificar la combinación óptima. Este análisis de realiza unicamente con el datset de train para que los valores de test no influyan en este procedimiento.\\

En la tabla \ref{tab:top_10_rfe_accuracy_datasetAlternativa2} se detallan los mejores 10 modelos obtenidos a partir de toda la combinación posibles. El mejor modelo a juzgar por la métrica Accuracy es el que se entrena con todos los predictores disponibles.

Asimismo, en la figura \ref{fig:rfe_evolucion_accuracy_datasetAlternativa2} se puede observar la evolución de la mátrica accuracy en función de la cantidad de variables que toma el modelo. La dispersión en este caso está asociado a los distintos valores de accuracy que tiene cada modelo ejecutado en cross validation como así también está contemplado todas las combinaciones de variables posibles con la cantidad que marca el eje x.\\
Se puede observar que desde que la cantidad de variables es 15, el Accuracy obtenido es un valor muy próximo al máximo que se consigue con 23 variables. Por lo que, si se opta por este dataset y se lo quisiera explicar quizas sería mas sencillo con menos variables aunque sigue siendo una cantidad considerablemente alta para extraer conclusiones sencillas y dependerá mucho de la interacción entre ellas.\\


\begin{table}[!h]
	
	\caption{\label{tab:top_10_rfe_accuracy_datasetAlternativa2}Top 10 Modelos con cantidad de variables seleccionadas según Accuracy}
	\centering
	\begin{tabular}[t]{rrr}
		\toprule
		\rowcolor{black}  \multicolumn{1}{c}{\textcolor{white}{\textbf{Variables}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{media\_accuracy}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{media\_kappa}}}\\
		\midrule
		\rowcolor{gray!6}  23 & 0.7747542 & 0.5421768\\
		20 & 0.7736578 & 0.5399892\\
		\rowcolor{gray!6}  18 & 0.7732554 & 0.5390105\\
		15 & 0.7720421 & 0.5368054\\
		\rowcolor{gray!6}  21 & 0.7720411 & 0.5363012\\
		\addlinespace
		22 & 0.7714524 & 0.5355353\\
		\rowcolor{gray!6}  17 & 0.7710945 & 0.5346718\\
		16 & 0.7710278 & 0.5348438\\
		\rowcolor{gray!6}  19 & 0.7707567 & 0.5340365\\
		14 & 0.7673518 & 0.5279523\\
		\bottomrule
	\end{tabular}
\end{table}

\begin{figure}[!htb]
	\centering
	\includegraphics{imagenes/variables/rfe_evolucion_accuracy-1_alternativa2.pdf}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Evolución de l Métrica Accuracy en función de la cantidad de variables usadas por el modelo}
	\label{fig:rfe_evolucion_accuracy_datasetAlternativa2}
\end{figure}

\paragraph{influencia de variables}
Tras ajustar cada modelo, se recalcula la influencia de cada variable.
De esta forma, para cada tamaño de modelo, se obtiene un ranking de la
importancia promedio de las variables. Los resultados se pueden observar en \ref{tab:tf_rfe_influencia_variables_23} y \ref{fig:rfe_influencia_var_dsalternativa2}. Se puede observar que la influencia sobre el resultado final ahora es mas equitativo entre las variables.


\begin{table}[!h]
	
	\caption{\label{tab:tf_rfe_influencia_variables_23}Influencia de variables en el resultado}
	\centering
	\begin{tabular}[t]{lrr}
		\toprule
		\rowcolor{black}  \multicolumn{1}{c}{\textcolor{white}{\textbf{var}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{media\_influencia}}} & \multicolumn{1}{c}{\textcolor{white}{\textbf{sd\_influencia}}}\\
		\midrule
		\rowcolor{gray!6}  tipo\_de\_aprobacion\_libre & 50.79648 & 2.5524875\\
		Turno\_Tarde & 44.59747 & 0.8908022\\
		\rowcolor{gray!6}  Turno\_Noche & 43.09091 & 1.1487629\\
		tipo\_de\_aprobacion\_no\_firmo & 42.65281 & 1.5211102\\
		\rowcolor{gray!6}  Aprobado & 42.15115 & 2.1368377\\
		\addlinespace
		tipo\_de\_aprobacion\_firmo & 40.75425 & 1.1106366\\
		\rowcolor{gray!6}  Turno\_Manana & 40.69317 & 1.9193145\\
		Nota\_max\_prom & 40.54109 & 1.7290803\\
		\rowcolor{gray!6}  cant\_recursada\_regular\_No\_Recurso & 36.59649 & 1.7624988\\
		cant\_resursada\_regular & 36.06834 & 1.6028767\\
		\addlinespace
		\rowcolor{gray!6}  edad\_al\_ingreso & 34.36706 & 2.0057595\\
		cant\_recursada\_regular\_Recurso1vez & 33.45997 & 1.0793458\\
		\rowcolor{gray!6}  noAprobado & 32.05701 & 1.4956207\\
		tipo\_de\_aprobacion\_cambio\_curso & 32.04880 & 1.2241621\\
		\rowcolor{gray!6}  tipo\_de\_aprobacion\_promociono & 30.37739 & 0.4212574\\
		\addlinespace
		Promociono & 30.31098 & 1.9463734\\
		\rowcolor{gray!6}  Nota & 30.01460 & 1.9773123\\
		EsTecnico\_X1 & 24.08818 & 1.1924095\\
		\rowcolor{gray!6}  cant\_recursada\_regular\_Recurso2vez & 23.93968 & 1.2196074\\
		Sexo\_M & 18.84818 & 2.2983891\\
		\addlinespace
		\rowcolor{gray!6}  cant\_recursada\_regular\_Recurso3vez & 17.05511 & 1.4083702\\
		EsTecnico\_SinDato & 16.70716 & 1.3843021\\
		\rowcolor{gray!6}  cant\_recursada\_regular\_Recurso4vez & 13.33266 & 1.3074133\\
		\bottomrule
	\end{tabular}
\end{table}


\begin{figure}[!htb]
	\centering
	\includegraphics{imagenes/variables/influencia_de_variables_23-1.pdf}
	%\includegraphics[width=0.25\textwidth]{mesh}
	\caption{Influencia de las variables mas importantes sobre el resultado}
	\label{fig:rfe_influencia_var_dsalternativa2}
\end{figure}



